{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-21-9a4e91911a60>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-21-9a4e91911a60>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    jai bhuriya baba ji/om nmay shivay\u001b[0m\n\u001b[0m              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "jai bhuriya baba ji/om nmay shivay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import sqlite3\n",
    "\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "import string\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "from sklearn import cross_validation\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "import sys, os\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=sqlite3.connect(\"database.sqlite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "filtered_data=pd.read_sql_query(\"\"\"\n",
    "SELECT *\n",
    "FROM Reviews\n",
    "WHERE Score !=3\n",
    "\"\"\",data)\n",
    "def partition(x):\n",
    "    if x<3:\n",
    "        return 'negative'\n",
    "    return 'positive'\n",
    "a_score=filtered_data[\"Score\"]\n",
    "positiveNegative=a_score.map(partition)\n",
    "filtered_data[\"Score\"]=positiveNegative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(525814, 10)\n"
     ]
    }
   ],
   "source": [
    "print(filtered_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>B001E4KFG0</td>\n",
       "      <td>A3SGXH7AUHU8GW</td>\n",
       "      <td>delmartian</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "      <td>1303862400</td>\n",
       "      <td>Good Quality Dog Food</td>\n",
       "      <td>I have bought several of the Vitality canned d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>B00813GRG4</td>\n",
       "      <td>A1D87F6ZCVE5NK</td>\n",
       "      <td>dll pa</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>negative</td>\n",
       "      <td>1346976000</td>\n",
       "      <td>Not as Advertised</td>\n",
       "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>B000LQOCH0</td>\n",
       "      <td>ABXLMWJIXXAIN</td>\n",
       "      <td>Natalia Corres \"Natalia Corres\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "      <td>1219017600</td>\n",
       "      <td>\"Delight\" says it all</td>\n",
       "      <td>This is a confection that has been around a fe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>B000UA0QIQ</td>\n",
       "      <td>A395BORC6FGVXV</td>\n",
       "      <td>Karl</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>negative</td>\n",
       "      <td>1307923200</td>\n",
       "      <td>Cough Medicine</td>\n",
       "      <td>If you are looking for the secret ingredient i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>B006K2ZZ7K</td>\n",
       "      <td>A1UQRSCLF8GW1T</td>\n",
       "      <td>Michael D. Bigham \"M. Wassir\"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>positive</td>\n",
       "      <td>1350777600</td>\n",
       "      <td>Great taffy</td>\n",
       "      <td>Great taffy at a great price.  There was a wid...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id   ProductId          UserId                      ProfileName  \\\n",
       "0   1  B001E4KFG0  A3SGXH7AUHU8GW                       delmartian   \n",
       "1   2  B00813GRG4  A1D87F6ZCVE5NK                           dll pa   \n",
       "2   3  B000LQOCH0   ABXLMWJIXXAIN  Natalia Corres \"Natalia Corres\"   \n",
       "3   4  B000UA0QIQ  A395BORC6FGVXV                             Karl   \n",
       "4   5  B006K2ZZ7K  A1UQRSCLF8GW1T    Michael D. Bigham \"M. Wassir\"   \n",
       "\n",
       "   HelpfulnessNumerator  HelpfulnessDenominator     Score        Time  \\\n",
       "0                     1                       1  positive  1303862400   \n",
       "1                     0                       0  negative  1346976000   \n",
       "2                     1                       1  positive  1219017600   \n",
       "3                     3                       3  negative  1307923200   \n",
       "4                     0                       0  positive  1350777600   \n",
       "\n",
       "                 Summary                                               Text  \n",
       "0  Good Quality Dog Food  I have bought several of the Vitality canned d...  \n",
       "1      Not as Advertised  Product arrived labeled as Jumbo Salted Peanut...  \n",
       "2  \"Delight\" says it all  This is a confection that has been around a fe...  \n",
       "3         Cough Medicine  If you are looking for the secret ingredient i...  \n",
       "4            Great taffy  Great taffy at a great price.  There was a wid...  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(364173, 10)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_data=filtered_data.sort_values('ProductId',ascending=True,inplace=False,kind='quickSort',na_position='last')\n",
    "#de duplication of entries\n",
    "final=sorted_data.drop_duplicates(subset={'UserId','ProfileName','Time','Text'},keep='first',inplace=False)\n",
    "final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(364171, 10)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "positive    307061\n",
       "negative     57110\n",
       "Name: Score, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final=final[final.HelpfulnessNumerator <= final.HelpfulnessDenominator]\n",
    "print(final.shape)\n",
    "#How many positive and negative reviews are present in our dataset?\n",
    "final['Score'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'yourself', 'mightn', 'for', 'are', 'hadn', \"hadn't\", 'themselves', \"won't\", 'into', 'his', \"didn't\", 'll', 'having', 'until', 'on', 'that', 'am', 'when', 'again', 'up', 'isn', 'down', 'because', 'and', \"it's\", \"hasn't\", 'ourselves', 'these', 'those', 'itself', 'once', 'some', 'do', 'a', 'above', \"you've\", 'only', 'they', 'myself', 'being', 'doing', 'their', 'further', 'at', \"mightn't\", 'm', 'its', 'been', 'by', 'why', 'just', 'here', 'ma', \"wouldn't\", 'what', 'we', 'she', 'theirs', 'who', 'so', 'while', 'with', 't', \"mustn't\", 'after', 'about', 'had', 'if', 'did', \"isn't\", 'the', \"you'll\", 'or', 'than', 'during', 'which', 'between', 'does', \"shouldn't\", 'over', 'mustn', 'will', 'shouldn', 'our', 'is', 'an', 'below', 'have', 'was', \"should've\", 'haven', 'hasn', \"needn't\", 'herself', \"don't\", 's', 'don', 'shan', \"couldn't\", 'were', 'from', \"wasn't\", 'me', \"doesn't\", 'be', 'other', 'needn', 'ain', 'whom', 'has', 'your', 'my', 'you', \"weren't\", 've', 'any', 'didn', 'not', 'as', 'of', 'can', 'i', 'this', 'he', 'same', 'yourselves', 'her', 'where', 'him', 'should', 'them', 'few', 'then', 're', \"that'll\", 'both', 'in', 'each', 'too', 'no', 'weren', 'won', 'yours', 'ours', 'how', \"aren't\", 'out', 'all', 'very', 'y', 'under', 'own', 'against', 'nor', 'but', 'hers', 'o', 'before', 'aren', 'more', 'himself', 'there', 'such', 'now', 'through', 'couldn', 'it', 'wasn', 'to', \"haven't\", \"you're\", \"you'd\", 'd', \"shan't\", 'off', 'wouldn', 'most', 'doesn', \"she's\"}\n",
      "tasti\n",
      "CPU times: user 1.73 ms, sys: 0 ns, total: 1.73 ms\n",
      "Wall time: 968 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import re\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "stop=set(stopwords.words('english'))\n",
    "print(stop)\n",
    "sno=nltk.stem.SnowballStemmer('english')\n",
    "print(sno.stem('tasty'))\n",
    "\n",
    "def cleanhtml(sentence):#function to clean the word of any html-tags\n",
    "    cleanr=re.compile('<.*?>')\n",
    "    cleantext=re.sub(cleanr,'',sentence)\n",
    "    return cleantext\n",
    "def cleanpunc(sentence):#function to clean the word of any punctuation or special characters\n",
    "    cleaned=re.sub(r'[!|?|<|,|/|.]',r'',sentence)\n",
    "    cleaned=re.sub(r'[;|\"|\\|)]',r'',cleaned)\n",
    "    return cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6min 8s, sys: 415 ms, total: 6min 9s\n",
      "Wall time: 6min 9s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "#Code for implementing step-by-step the checks mentioned in the pre-processing phase\n",
    "j=0\n",
    "str1=''\n",
    "sn=''\n",
    "final_string=[]\n",
    "positive_R=[]\n",
    "negative_R=[]\n",
    "for sent in final['Text'].values:\n",
    "    filtered_sentence=[]\n",
    "    #print(sent)\n",
    "    sent=cleanhtml(sent)#remove html tags\n",
    "    for w in sent.split():\n",
    "        for cleaned_words in cleanpunc(w).split():\n",
    "            if(cleaned_words.isalpha())& (len(cleaned_words)>2):\n",
    "                if(cleaned_words.lower() not in stop):\n",
    "                    sn=(sno.stem(cleaned_words.lower())).encode('utf8')\n",
    "                    filtered_sentence.append(sn)\n",
    "                    if(final['Score'].values)[j]=='positive':\n",
    "                        positive_R.append(sn)\n",
    "                    if(final['Score'].values)[j]=='negative':\n",
    "                        negative_R.append(sn)\n",
    "                        \n",
    "                else:\n",
    "                    continue\n",
    "            else:\n",
    "                continue\n",
    "       #print(filtered_sentance)\n",
    "    str1=b\" \".join(filtered_sentence) #final string of clean_words\n",
    "    #print(\"@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\")\n",
    "    final_string.append(str1)\n",
    "    j+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "final['cleaned_Text']=final_string #adding a column of CleanedText which displays the data after pre-processing of the review\n",
    "final['cleaned_Text']=final['cleaned_Text'].str.decode('utf-8')\n",
    "print(final.head(3))\n",
    "\n",
    "\n",
    "print(final.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.44 s, sys: 40 ms, total: 2.48 s\n",
      "Wall time: 849 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from datetime import timedelta\n",
    "#sorting based on time\n",
    "#final['Time']=pd.to_datetime(final['Time'])\n",
    "final['Time']=pd.to_datetime(final.Time)\n",
    "\n",
    "final=final.sort_values('Time',ascending=True,inplace=False,kind='quickSort',na_position='last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "      <th>cleaned_Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>138706</th>\n",
       "      <td>150524</td>\n",
       "      <td>0006641040</td>\n",
       "      <td>ACITT7DI6IDDL</td>\n",
       "      <td>shari zychinski</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>positive</td>\n",
       "      <td>1970-01-01 00:00:00.939340800</td>\n",
       "      <td>EVERY book is educational</td>\n",
       "      <td>this witty little book makes my son laugh at l...</td>\n",
       "      <td>witti littl book make son laugh loud recit car...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138683</th>\n",
       "      <td>150501</td>\n",
       "      <td>0006641040</td>\n",
       "      <td>AJ46FKXOVC7NR</td>\n",
       "      <td>Nicholas A Mesiano</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>positive</td>\n",
       "      <td>1970-01-01 00:00:00.940809600</td>\n",
       "      <td>This whole series is great way to spend time w...</td>\n",
       "      <td>I can remember seeing the show when it aired o...</td>\n",
       "      <td>rememb see show air televis year ago child sis...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Id   ProductId         UserId         ProfileName  \\\n",
       "138706  150524  0006641040  ACITT7DI6IDDL     shari zychinski   \n",
       "138683  150501  0006641040  AJ46FKXOVC7NR  Nicholas A Mesiano   \n",
       "\n",
       "        HelpfulnessNumerator  HelpfulnessDenominator     Score  \\\n",
       "138706                     0                       0  positive   \n",
       "138683                     2                       2  positive   \n",
       "\n",
       "                                Time  \\\n",
       "138706 1970-01-01 00:00:00.939340800   \n",
       "138683 1970-01-01 00:00:00.940809600   \n",
       "\n",
       "                                                  Summary  \\\n",
       "138706                          EVERY book is educational   \n",
       "138683  This whole series is great way to spend time w...   \n",
       "\n",
       "                                                     Text  \\\n",
       "138706  this witty little book makes my son laugh at l...   \n",
       "138683  I can remember seeing the show when it aired o...   \n",
       "\n",
       "                                             cleaned_Text  \n",
       "138706  witti littl book make son laugh loud recit car...  \n",
       "138683  rememb see show air televis year ago child sis...  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = final['cleaned_Text'].iloc[0:80000], final['Score'].iloc[0:80000]\n",
    "#X_cv, y_cv = final['cleaned_Text'].iloc[60000:80000], final['Score'].iloc[60000:80000]\n",
    "X_test, y_test = final['cleaned_Text'].iloc[80000:100000], final['Score'].iloc[80000:100000]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.BOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(80000, 67317) (20000, 67317)\n"
     ]
    }
   ],
   "source": [
    "#BoW\n",
    "count_vect = CountVectorizer()\n",
    "count_vect.fit(X_train)\n",
    "X_train=count_vect.transform(X_train)\n",
    "#X_cv=count_vect.transform(X_cv)\n",
    "X_test=count_vect.transform(X_test)\n",
    "print(X_train.shape,X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<20000x67317 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 580348 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Standerdized the data\n",
    "scaler = StandardScaler(with_mean=False)\n",
    "scaler.fit(X_train)\n",
    "scaler.transform(X_train)\n",
    "scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.datasets import *\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "tuned_parameters = [{'C': [10**-4, 10**-2, 10**0, 10**2, 10**4]}]\n",
    "#Using GridSearchCV\n",
    "\n",
    "# Create a linear SVM classifier \n",
    "\n",
    "model = GridSearchCV(svm.SVC(kernel='linear',class_weight='balanced'), tuned_parameters, scoring = 'accuracy', cv=5)\n",
    "model.fit(X_train,y_train)\n",
    "\n",
    "\n",
    "print(model.best_estimator_)\n",
    "\n",
    "\n",
    "\n",
    "print(\"best_score\")\n",
    "print(model.best_score_)\n",
    "\n",
    "\n",
    "\n",
    "print('Parameters')\n",
    "print(model.best_params_)\n",
    "\n",
    "\n",
    "\n",
    "print(model.score(X_test,y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = svm.SVC(kernel='linear', C=1...,class_weight='balanced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train classifier \n",
    "clf.fit(X_train, y_train)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot decision function on training and test data\n",
    "plot_decision_function(X_train, y_train, X_test, y_test, clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on unseen test data\n",
    "clf_predictions = clf.predict(X_test)\n",
    "print(\"Accuracy: {}%\".format(clf.score(X_test, y_test) * 100 ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cv = CountVectorizer()\n",
    "#cv.fit(data)\n",
    "print len(count_vect.vocabulary_)\n",
    "print count_vect.get_feature_names()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_coefficients(classifier, feature_names, top_features=20):\n",
    "    coef = classifier.coef_.ravel()\n",
    "    top_positive_coefficients = np.argsort(coef)[-top_features:]\n",
    "    top_negative_coefficients = np.argsort(coef)[:top_features]\n",
    "    top_coefficients = np.hstack([top_negative_coefficients, top_positive_coefficients])\n",
    " # create plot\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    colors = [‘red’ if c < 0 else ‘blue’ for c in coef[top_coefficients]]\n",
    "    plt.bar(np.arange(2 * top_features), coef[top_coefficients], color=colors)\n",
    "    feature_names = np.array(feature_names)\n",
    "    plt.xticks(np.arange(1, 1 + 2 * top_features), feature_names[top_coefficients], rotation=60, ha=’right’)\n",
    "    plt.show()\n",
    "\n",
    "#cv = CountVectorizer()\n",
    "#cv.fit(data)\n",
    "#print len(cv.vocabulary_)\n",
    "#print cv.get_feature_names()\n",
    "#X_train = cv.transform(data)\n",
    "\n",
    "#svm = LinearSVC()\n",
    "#svm.fit(X_train, y_train)\n",
    "\n",
    "plot_coefficients(clf, count_vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_coefficients(classifier, feature_names, top_features=20):\n",
    " coef = classifier.coef_.ravel()\n",
    " top_positive_coefficients = np.argsort(coef)[-top_features:]\n",
    " top_negative_coefficients = np.argsort(coef)[:top_features]\n",
    " top_coefficients = np.hstack([top_negative_coefficients, top_positive_coefficients])\n",
    " # create plot\n",
    " plt.figure(figsize=(15, 5))\n",
    " colors = [‘red’ if c < 0 else ‘blue’ for c in coef[top_coefficients]]\n",
    " plt.bar(np.arange(2 * top_features), coef[top_coefficients], color=colors)\n",
    " feature_names = np.array(feature_names)\n",
    " plt.xticks(np.arange(1, 1 + 2 * top_features), feature_names[top_coefficients], rotation=60, ha=’right’)\n",
    " plt.show()\n",
    "\n",
    "cv = CountVectorizer()\n",
    "cv.fit(data)\n",
    "print len(cv.vocabulary_)\n",
    "print cv.get_feature_names()\n",
    "\n",
    "X_train = cv.transform(data)\n",
    "\n",
    "svm = LinearSVC()\n",
    "svm.fit(X_train, target)\n",
    "\n",
    "plot_coefficients(svm, cv.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Search Linear SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn import svm\n",
    "from scipy.stats import uniform\n",
    "#tuned_parameter = [{'C': [10**-3, 10**-2, 10**0, 10**2, 10**3]}]\n",
    "tuned_parameter = {'C':uniform()}\n",
    "model1 = RandomizedSearchCV(svm.SVC(kernel='linear',class_weight='balanced'),tuned_parameters, scoring = 'accuracy', cv=5)\n",
    "model1.fit(X_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model1.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"best_score\")\n",
    "print(model1.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Parameters')\n",
    "print(model1.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model1.score(X_test,y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = svm.SVC(kernel='linear', C=1..............,class_weight='balanced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot decision function on training and test data\n",
    "plot_decision_function(X_train, y_train, X_test, y_test, clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on unseen test data\n",
    "clf_predictions = clf.predict(X_test)\n",
    "print(\"Accuracy: {}%\".format(clf.score(X_test, y_test) * 100 ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM-RBF-GridsearchCv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "svd=TruncatedSVD(n_components=300)\n",
    "X_train = svd.fit_transform(X_train)\n",
    "X_test = svd.fit_transform(X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "tuned_parameters = [{'C': [10**-4, 10**-2, 10**0, 10**2, 10**4],'gamma':[10**-4, 10**-2, 10**0, 10**2, 10**4]}]\n",
    "#Using GridSearchCV\n",
    "\n",
    "# Create a linear SVM classifier \n",
    "\n",
    "\n",
    "model = GridSearchCV(svm.SVC(kernel= 'rbf',class_weight='balanced'), tuned_parameters, scoring = 'accuracy', cv=5)\n",
    "\n",
    "model.fit(X_train,y_train)\n",
    "\n",
    "print(model.best_estimator_)\n",
    "\n",
    "\n",
    "print(\"best_score\")\n",
    "print(model.best_score_)\n",
    "\n",
    "\n",
    "print('Parameters')\n",
    "print(model.best_params_)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#model_mean_scores = [result.mean_validation_score for result in model.grid_scores_]\n",
    "print(model.score(X_test,y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create SVM classifier based on RBF kernel. \n",
    "clf = svm.SVC(kernel='rbf', C = 10.0...................., gamma=0.1................................,class_weight='balanced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot decision function on training and test data\n",
    "plot_decision_function(X_train, y_train, X_test, y_test, clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy: {}%\".format(clf.score(X_test, y_test) * 100 ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random SearchCV-RBF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import uniform\n",
    "from sklearn import svm\n",
    "\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "svd=TruncatedSVD(n_components=300)\n",
    "X_train = svd.fit_transform(X_train)\n",
    "X_test = svd.fit_transform(X_test)\n",
    "\n",
    "\n",
    "\n",
    "tuned_parameter = {'C':uniform()}\n",
    "model2 = RandomizedSearchCV(svm.SVC(kernel='rbf',class_weight='balanced'),tuned_parameters, scoring = 'accuracy', cv=5)\n",
    "model2.fit(X_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model2.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"best_score\")\n",
    "print(model2.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Parameters')\n",
    "print(model2.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model2.score(X_test,y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create SVM classifier based on RBF kernel. \n",
    "clf = svm.SVC(kernel='rbf', C = 10.0...................., gamma=0.1................................,class_weight='balanced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot decision function on training and test data\n",
    "plot_decision_function(X_train, y_train, X_test, y_test, clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy: {}%\".format(clf.score(X_test, y_test) * 100 ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = final['cleaned_Text'].iloc[0:80000], final['Score'].iloc[0:80000]\n",
    "#X_cv, y_cv = final['cleaned_Text'].iloc[60000:80000], final['Score'].iloc[60000:80000]\n",
    "X_test, y_test = final['cleaned_Text'].iloc[80000:100000], final['Score'].iloc[80000:100000]\n",
    "\n",
    "\n",
    "\n",
    "#Initializing tfidf vectorizer\n",
    "tfidf_vect = TfidfVectorizer()\n",
    "\n",
    "#Fitting for tfidf vectorization\n",
    "tfidf_vect.fit(X_train)\n",
    "X_train= tfidf_vect.transform(X_train)\n",
    "X_test = tfidf_vect.transform(X_test)\n",
    "#X_cv = tfidf_vect.transform(X_cv)\n",
    "X_train.shape,y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standerdized the data\n",
    "scaler = StandardScaler(with_mean=False)\n",
    "scaler.fit(X_train)\n",
    "scaler.transform(X_train)\n",
    "scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GridSearchCV-LinearSVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.datasets import *\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "\n",
    "tuned_parameters = [{'C': [10**-4, 10**-2, 10**0, 10**2, 10**4]}]\n",
    "#Using GridSearchCV\n",
    "\n",
    "# Create a linear SVM classifier \n",
    "\n",
    "model = GridSearchCV(svm.SVC(kernel='linear',class_weight='balanced'), tuned_parameters, scoring = 'accuracy', cv=5)\n",
    "model.fit(X_train,y_train)\n",
    "\n",
    "print(model.best_estimator_)\n",
    "\n",
    "\n",
    "print(\"best_score\")\n",
    "print(model.best_score_)\n",
    "\n",
    "\n",
    "print('Parameters')\n",
    "print(model.best_params_)\n",
    "\n",
    "\n",
    "print(model.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = svm.SVC(kernel='linear', C=1..............,class_weight='balanced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train classifier \n",
    "clf.fit(X_train, y_train)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot decision function on training and test data\n",
    "plot_decision_function(X_train, y_train, X_test, y_test, clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on unseen test data\n",
    "clf_predictions = clf.predict(X_test)\n",
    "print(\"Accuracy: {}%\".format(clf.score(X_test, y_test) * 100 ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #  Random Search Linear SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import uniform\n",
    "from sklearn import svm\n",
    "#tuned_parameter = [{'C': [10**-3, 10**-2, 10**0, 10**2, 10**3]}]\n",
    "tuned_parameter = {'C':uniform()}\n",
    "model1 = RandomizedSearchCV(svm.SVC(kernel='linear',class_weight='balanced'),tuned_parameters, scoring = 'accuracy', cv=5)\n",
    "model1.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model1.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"best_score\")\n",
    "print(model1.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Parameters')\n",
    "print(model1.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model1.score(X_test,y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = svm.SVC(kernel='linear', C=1..............,class_weight='balanced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot decision function on training and test data\n",
    "plot_decision_function(X_train, y_train, X_test, y_test, clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on unseen test data\n",
    "clf_predictions = clf.predict(X_test)\n",
    "print(\"Accuracy: {}%\".format(clf.score(X_test, y_test) * 100 ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # SVM-RBF-Gridsearch-Tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "svd=TruncatedSVD(n_components=300)\n",
    "X_train = svd.fit_transform(X_train)\n",
    "X_test = svd.fit_transform(X_test)\n",
    "\n",
    "tuned_parameters = [{'C': [10**-4, 10**-2, 10**0, 10**2, 10**4],'gamma':[10**-4, 10**-2, 10**0, 10**2, 10**4]}]\n",
    "#Using GridSearchCV\n",
    "\n",
    "# Create a linear SVM classifier \n",
    "\n",
    "\n",
    "model = GridSearchCV(svm.SVC(kernel= 'rbf',class_weight='balanced'), tuned_parameters, scoring = 'accuracy', cv=5)\n",
    "\n",
    "model.fit(X_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"best_score\")\n",
    "print(model.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Parameters')\n",
    "print(model.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(model.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create SVM classifier based on RBF kernel. \n",
    "clf = svm.SVC(kernel='rbf', C = 10.0...................., gamma=0.1................................,class_weight='balanced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot decision function on training and test data\n",
    "plot_decision_function(X_train, y_train, X_test, y_test, clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy: {}%\".format(clf.score(X_test, y_test) * 100 ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RandomeSearchCV-RBF-Tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import uniform\n",
    "from sklearn import svm\n",
    "#tuned_parameter = [{'C': [10**-3, 10**-2, 10**0, 10**2, 10**3]}]\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "svd=TruncatedSVD(n_components=300)\n",
    "X_train = svd.fit_transform(X_train)\n",
    "X_test = svd.fit_transform(X_test)\n",
    "\n",
    "\n",
    "\n",
    "tuned_parameter = {'C':uniform()}\n",
    "model1 = RandomizedSearchCV(svm.SVC(kernel='rbf',class_weight='balanced'),tuned_parameters, scoring = 'accuracy', cv=5)\n",
    "model1.fit(X_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"best_score\")\n",
    "print(model.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Parameters')\n",
    "print(model.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create SVM classifier based on RBF kernel. \n",
    "clf = svm.SVC(kernel='rbf', C = 10.0...................., gamma=0.1................................,class_weight='balanced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot decision function on training and test data\n",
    "plot_decision_function(X_train, y_train, X_test, y_test, clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy: {}%\".format(clf.score(X_test, y_test) * 100 ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.WORD2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def cleanhtml(sentence): #function to clean the word of any html-tags\n",
    "    cleanr = re.compile('<.*?>')\n",
    "    cleantext = re.sub(cleanr, ' ', sentence)\n",
    "    return cleantext\n",
    "def cleanpunc(sentence): #function to clean the word of any punctuation or special characters\n",
    "    cleaned = re.sub(r'[?|!|\\'|\"|#]',r'',sentence)\n",
    "    cleaned = re.sub(r'[.|,|)|(|\\|/]',r' ',cleaned)\n",
    "    return  cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train your own Word2Vec model using your own train text corpus\n",
    "#spliting the data\n",
    "X_train, y_train = final['cleaned_Text'].iloc[0:80000],final['Score'].iloc[0:80000]\n",
    "#X_cv, y_cv = final['cleaned_Text'].iloc[60000:80000],final['Score'].iloc[60000:80000]\n",
    "X_test, y_test = final['cleaned_Text'].iloc[80000:100000],final['Score'].iloc[80000:100000]\n",
    "print(X_train.shape,y_train.shape,X_test.shape,y_test.shape)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim import utils\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models import KeyedVectors\n",
    "import pickle\n",
    "from gensim import parsing, corpora, matutils, interfaces, models, similarities, summarization, utils\n",
    "\n",
    "\n",
    "train_sent=[]\n",
    "\n",
    "for sent in X_train:\n",
    "    filtered_sentence=[]\n",
    "    sent=cleanhtml(sent)\n",
    "    for w in sent.split():\n",
    "        for cleaned_words in cleanpunc(w).split():\n",
    "            if(cleaned_words.isalpha()):    \n",
    "                filtered_sentence.append(cleaned_words.lower())\n",
    "            else:\n",
    "                continue \n",
    "    train_sent.append(filtered_sentence)\n",
    "print(len(train_sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sent=[]\n",
    "\n",
    "for sent in X_test:\n",
    "    filtered_sentence=[]\n",
    "    sent=cleanhtml(sent)\n",
    "    for w in sent.split():\n",
    "        for cleaned_words in cleanpunc(w).split():\n",
    "            if(cleaned_words.isalpha()):    \n",
    "                filtered_sentence.append(cleaned_words.lower())\n",
    "            else:\n",
    "                continue \n",
    "    test_sent.append(filtered_sentence)\n",
    "print(len(test_sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_w2v_model = gensim.models.Word2Vec(train_sent,min_count=5,size=50,workers=4)\n",
    "train_words = list(train_w2v_model.wv.vocab)\n",
    "print(len(train_words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.1 AvgW2v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#avg w2v\n",
    "#Avg-w2v for train data\n",
    "\n",
    "train_vectors = []\n",
    "for sent in tqdm(train_sent):\n",
    "    train_vec = np.zeros(50)\n",
    "    cnt_words = 0\n",
    "    for word in sent:\n",
    "        try:\n",
    "            vec=train_w2v_model.wv[word]\n",
    "            train_vec+=vec\n",
    "            cnt_words+=1\n",
    "        except:\n",
    "            pass\n",
    "    train_vec/=cnt_words\n",
    "    train_vectors.append(train_vec)\n",
    "print(len(train_vectors))\n",
    "print(len(train_vectors[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#Avg-w2v for test data\n",
    "test_vectors = []\n",
    "for sent in tqdm(test_sent):\n",
    "    test_vec = np.zeros(50)\n",
    "    cnt_words = 0\n",
    "    for word in sent:\n",
    "        try:\n",
    "            vec=train_w2v_model.wv[word]\n",
    "            test_vec+=vec\n",
    "            cnt_words+=1\n",
    "        except:\n",
    "            pass\n",
    "    test_vec/=cnt_words\n",
    "    test_vectors.append(test_vec)\n",
    "print(len(test_vectors))\n",
    "print(len(test_vectors[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_vectors\n",
    "\n",
    "X_test = test_vectors\n",
    "print(len(X_train),len(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # TFIDF-W2v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TFIDF-W2V\n",
    "\n",
    "\n",
    "X_train, y_train = final['cleaned_Text'].iloc[0:60000], final['Score'].iloc[0:60000]\n",
    "X_cv, y_cv = final['cleaned_Text'].iloc[60000:80000], final['Score'].iloc[60000:80000]\n",
    "X_test, y_test = final['cleaned_Text'].iloc[80000:100000], final['Score'].iloc[80000:100000]\n",
    "\n",
    "# Initializing tfidf vectorizer\n",
    "tfidf_vect = TfidfVectorizer(ngram_range=(1, 1))\n",
    "\n",
    "# Fitting for tfidf vectorization\n",
    "tfidf_vect.fit(X_train)\n",
    "X_train = tfidf_vect.transform(X_train)\n",
    "X_test = tfidf_vect.transform(X_test)\n",
    "X_cv = tfidf_vect.transform(X_cv)\n",
    "#we are converting dictionary with word as key and idf as value\n",
    "dictionary = dict(zip(tfidf_vect.get_feature_names(),list(tfidf_vect.idf_)))\n",
    "print(X_train.shape,y_train.shape)\n",
    "\n",
    "\n",
    "#tfidf_feat=tfidf_vect.get_feature_names()# tfidf word/col names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "tfidf_feat = tfidf_vect.get_feature_names()\n",
    "tfidf_train_vectors = []\n",
    "row = 0\n",
    "for sent in tqdm(train_sent):\n",
    "    sent_vec = np.zeros(50)\n",
    "    weight_sum = 0\n",
    "    for word in sent:\n",
    "        try:\n",
    "            vec = train_w2v_model.wv[word]\n",
    "            #tf_idf = X_train[row, tfidf_feat.index(word)](prev.............)\n",
    "            # to reduce the computation we are \n",
    "            # dictionary[word] = idf value of word in whole courpus\n",
    "            # sent.count(word) = tf valeus of word in this review\n",
    "            tf_idf = dictionary[word]*(sent.count(word)/len(sent))\n",
    "            sent_vec += (vec * tf_idf)\n",
    "            weight_sum += tf_idf\n",
    "        except:\n",
    "            pass\n",
    "    if weight_sum != 0:\n",
    "        sent_vec /= weight_sum\n",
    "    tfidf_train_vectors.append(sent_vec)\n",
    "    row += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(tfidf_train_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#tfidf w2v for cv data\n",
    "tfidf_feat = tfidf_vect.get_feature_names()\n",
    "tfidf_cv_vectors = []; # the tfidf-w2v for each sentence/review is stored in this list\n",
    "row=0;\n",
    "for sent in cv_sent: # for each review/sentence\n",
    "    cv_vec = np.zeros(50) # as word vectors are of zero length\n",
    "    weight_sum =0; # num of words with a valid vector in the sentence/review\n",
    "    for word in sent: # for each word in a review/sentence\n",
    "        try:\n",
    "            vec = train_w2v_model.wv[word]\n",
    "            # obtain the tf_idf of a word in a sentence/review\n",
    "            #tf_idf = X_cv[row, tfidf_feat.index(word)]\n",
    "            tf_idf = dictionary[word]*(sent.count(word)/len(sent))\n",
    "            cv_vec += (vec * tf_idf)\n",
    "            weight_sum += tf_idf\n",
    "        except:\n",
    "            pass\n",
    "    cv_vec /= weight_sum\n",
    "    tfidf_cv_vectors.append(cv_vec)\n",
    "    row += 1\n",
    "len(tfidf_cv_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tfidf w2v for test data\n",
    "\n",
    "tfidf_test_vectors = []; # the tfidf-w2v for each sentence/review is stored in this list\n",
    "row=0;\n",
    "for sent in test_sent: # for each review/sentence\n",
    "    test_vec = np.zeros(50) # as word vectors are of zero length\n",
    "    weight_sum =0; # num of words with a valid vector in the sentence/review\n",
    "    for word in sent: # for each word in a review/sentence\n",
    "        try:\n",
    "            vec = train_w2v_model.wv[word]\n",
    "            # obtain the tf_idf of a word in a sentence/review\n",
    "            #tf_idf = X_test[row, tfidf_feat.index(word)]\n",
    "            tf_idf = dictionary[word]*(sent.count(word)/len(sent))\n",
    "            test_vec += (vec * tf_idf)\n",
    "            weight_sum += tf_idf\n",
    "        except:\n",
    "            pass\n",
    "    test_vec /= weight_sum\n",
    "    tfidf_test_vectors.append(test_vec)\n",
    "    row += 1\n",
    "len(tfidf_test_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = tfidf_train_vectors\n",
    "X_cv = tfidf_cv_vectors\n",
    "X_test = tfidf_test_vectors \n",
    "len(X_train)\n",
    "print(len(X_cv))\n",
    "print(len(y_cv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
